{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as np\n",
    "from jax import vmap\n",
    "import optax\n",
    "import numpy as onp\n",
    "import sys\n",
    "sys.path.append('../py')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import common.drifts as drifts\n",
    "import common.networks as networks\n",
    "import haiku as hk\n",
    "import common.grid_utils as grid_utils\n",
    "import launchers.few_particles_split_score as launcher\n",
    "import matplotlib.animation as animation\n",
    "from typing import Tuple, Dict, Callable\n",
    "from ml_collections import config_dict\n",
    "import functools\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "mpl.rcParams['axes.grid']           = True\n",
    "mpl.rcParams['axes.grid.which']     = 'both'\n",
    "mpl.rcParams['xtick.minor.visible'] = True\n",
    "mpl.rcParams['ytick.minor.visible'] = True\n",
    "mpl.rcParams['xtick.minor.visible'] = True\n",
    "mpl.rcParams['axes.facecolor']      = 'white'\n",
    "mpl.rcParams['grid.color']          = '0.8'\n",
    "mpl.rcParams['grid.alpha']          = '0.1'\n",
    "mpl.rcParams['text.usetex']         = True\n",
    "mpl.rcParams['font.family']         = 'serif'\n",
    "mpl.rcParams['figure.figsize']      = (8, 4)\n",
    "mpl.rcParams['figure.titlesize']    = 7.5\n",
    "mpl.rcParams['font.size']           = 10\n",
    "mpl.rcParams['legend.fontsize']     = 7.5\n",
    "mpl.rcParams['figure.dpi']          = 300\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/scratch/nb3397/results/mips/lowd_cates/'\n",
    "v0s         = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "s\n",
    "\n",
    "## score matching + PINN\n",
    "output_names = [\"7_26_23/7_26_23_N64_smaller_dt_0\",\n",
    "                \"8_6_23/compressed/8_6_23_N64_sm_pinn_only_a100_0\",\n",
    "                \"8_15_23/8_15_23_N64_sm_pinn_only_a100_extend_8_4_23_1_0_56.0\",\n",
    "                \"8_6_23/compressed/8_6_23_N64_sm_pinn_only_a100_2\",\n",
    "                \"8_6_23/compressed/8_6_23_N64_sm_pinn_only_a100_3\",\n",
    "                \"8_6_23/compressed/8_6_23_N64_sm_pinn_only_a100_4\"]\n",
    "\n",
    "data_dicts = {\n",
    "    v0: pickle.load(open(f'{base_folder}/{output_names[ii]}.npy', 'rb')) for ii, v0 in enumerate(v0s)\n",
    "\n",
    "\n",
    "N = data_dicts[0.0]['cfg'].N\n",
    "d = data_dicts[0.0]['cfg'].d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts[0.2]['xgs'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cfg_hashable(cfg: config_dict.ConfigDict):\n",
    "    \"\"\"Fix some non-hashable types in older versions of the code.\"\"\"\n",
    "    try:\n",
    "        del cfg.radii\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        float_width = float(cfg.width)\n",
    "        del cfg.width\n",
    "        cfg.width = float_width\n",
    "    except:\n",
    "        print('Already frozen!')\n",
    "\n",
    "    try:\n",
    "        float_sig0x = float(cfg.sig0x)\n",
    "        del cfg.sig0x\n",
    "        cfg.sig0x = float_sig0x\n",
    "    except:\n",
    "        print('Already frozen!')\n",
    " \n",
    "    return config_dict.FrozenConfigDict(cfg)\n",
    "\n",
    "\n",
    "def get_params(\n",
    "    data_dict: dict,\n",
    "    ema_fac: float\n",
    ") -> hk.Params:\n",
    "    \"\"\"Backwards compatibility for old saving routines.\"\"\"\n",
    "    try:\n",
    "        print(\"Trying to load via params_list.\")\n",
    "        if ema_fac > 0:\n",
    "            params = data_dict['ema_params_list'][-1][ema_fac]\n",
    "        else:\n",
    "            params = data_dict['params_list'][-1]\n",
    "        print('Success!')\n",
    "    except:\n",
    "        print(\"Failed! Loading params directly.\")\n",
    "        if ema_fac > 0:\n",
    "            params = data_dict['ema_params'][ema_fac]\n",
    "        else:\n",
    "            params = data_dict['params']\n",
    "        print('Success!')\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_traj_output_info = jax.jit(\n",
    "    jax.vmap(launcher.compute_output_info, in_axes=(0, None, None, None, None)), \n",
    "    static_argnums=(2, 3, 4)\n",
    ")\n",
    "\n",
    "\n",
    "def compute_particle_quantities(\n",
    "    batch_size: int,\n",
    "    average_xgs: np.ndarray, # [n_v0s, n_pts_average, 2N, d]\n",
    "    ema_fac: float\n",
    ") -> np.ndarray:\n",
    "    n_pts_average = average_xgs.shape[1]\n",
    "    assert(n_pts_average % batch_size == 0)\n",
    "    n_batches = n_pts_average // batch_size\n",
    "\n",
    "    ## obtain particle-based quantities for spatial averaging\n",
    "    n_v0s = len(v0s)\n",
    "    particle_quantities = {\n",
    "        'gdot':   onp.zeros((n_v0s, n_pts_average, N)),\n",
    "        'xdot':   onp.zeros((n_v0s, n_pts_average, N)),\n",
    "        'v':      onp.zeros((n_v0s, n_pts_average, N)),\n",
    "        'div_vg': onp.zeros((n_v0s, n_pts_average, N)),\n",
    "        'div_vx': onp.zeros((n_v0s, n_pts_average, N)),\n",
    "        'div_v':  onp.zeros((n_v0s, n_pts_average, N)),\n",
    "        'xs':     onp.zeros((n_v0s, n_pts_average, N, 2))\n",
    "    }\n",
    "\n",
    "\n",
    "    for kk, v0 in enumerate(v0s):\n",
    "        # unpack everything\n",
    "        data_dict   = data_dicts[v0]\n",
    "        cfg         = make_cfg_hashable(data_dict['cfg'])\n",
    "        params      = get_params(data_dict, ema_fac)\n",
    "        xgs         = average_xgs[kk]\n",
    "        xs, gs      = np.split(xgs, 2, axis=1)\n",
    "        particle_quantities['xs'][kk] = xs\n",
    "        score_net, particle_div_net, _, _ = launcher.construct_network(cfg)\n",
    "\n",
    "        # compute quantity of interest for spatial averaging\n",
    "        for curr_batch in range(n_batches):\n",
    "            lb = curr_batch*batch_size\n",
    "            ub = lb + batch_size\n",
    "            batch_outputs = compute_traj_output_info(xgs[lb:ub], params, cfg, score_net, particle_div_net)\n",
    "            \n",
    "            particle_quantities['gdot'][kk, lb:ub]   = batch_outputs[2]\n",
    "            particle_quantities['xdot'][kk, lb:ub]   = batch_outputs[3]\n",
    "            particle_quantities['v'][kk, lb:ub]      = np.linalg.norm(batch_outputs[7], axis=-1)\n",
    "            particle_quantities['div_vg'][kk, lb:ub] = batch_outputs[-3]\n",
    "            particle_quantities['div_vx'][kk, lb:ub] = batch_outputs[-4]\n",
    "            particle_quantities['div_v'][kk, lb:ub]  = batch_outputs[-5]\n",
    "            \n",
    "        print(f'Finished computing particle quantities for {kk+1}/{len(v0s)}')\n",
    "\n",
    "    return particle_quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On-Particle Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trajectories(\n",
    "    n_steps: int,\n",
    "    start_index: int,\n",
    ") -> np.ndarray: # [nv0s, n_steps, 2*N, d]\n",
    "    ## obtain particle-based quantities for spatial averaging\n",
    "    n_v0s = len(v0s)\n",
    "    trajs = onp.zeros((n_v0s, n_steps, 2*N, d))\n",
    "\n",
    "    for kk, v0 in enumerate(v0s):\n",
    "        # unpack everything\n",
    "        data_dict   = data_dicts[v0]\n",
    "        cfg         = make_cfg_hashable(data_dict['cfg'])\n",
    "        init = data_dict['xgs'][start_index]\n",
    "        _, trajs[kk] = launcher.rollout(init, onp.random.randn(n_steps, 2*N, d), cfg)\n",
    "        print(f'Finished trajectory {kk+1}/{n_v0s}.')\n",
    "\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radius_to_points(ax, radius):\n",
    "    \"\"\"Convert radius in axis units to radius in points, for use\n",
    "    with making scatterplots. Written by GPT4.\"\"\"\n",
    "    # Convert the radius from data units to display units (pixels)\n",
    "    pixel_radius = ax.transData.transform([(radius, radius)]) - ax.transData.transform([(0, 0)])\n",
    "    \n",
    "    # Compute the area of the circle in pixels²\n",
    "    area_pixels = np.pi * (pixel_radius[0, 0] ** 2)\n",
    "\n",
    "    # Convert the area from pixels² to points²\n",
    "    area_points = area_pixels / (plt.gcf().dpi / 72) ** 2\n",
    "    \n",
    "    return area_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_particle_plot(\n",
    "    quantities: np.ndarray,\n",
    "    xs_plot: np.ndarray,\n",
    "    normalize: bool,\n",
    "    clip_quantile: float,\n",
    "    title: str,\n",
    "    save_str: str\n",
    ") -> None:\n",
    "    # common plot parameters\n",
    "    plt.close('all')\n",
    "    sns.set_palette('deep')\n",
    "    fw, fh    = 4, 5.5\n",
    "    fraction  = 0.15\n",
    "    pad       = 0.025\n",
    "    shrink    = 0.5\n",
    "    fontsize  = 20\n",
    "    \n",
    "    # normalize by v0\n",
    "    if normalize:\n",
    "        quantities = quantities / (np.array(v0s) + 1e-4)[:quantities.shape[0], None]\n",
    "        title      = title + r\"$/v_0$\"\n",
    "\n",
    "\n",
    "    # individual panels\n",
    "    titles = [rf\"$v_0={v0}$\" for v0 in v0s[:quantities.shape[0]]]\n",
    "    cmap   = sns.color_palette('mako', as_cmap=True)\n",
    "    nrows  = 1\n",
    "    ncols  = len(titles)\n",
    "\n",
    "\n",
    "    # set up the figure\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=nrows, ncols=ncols, figsize=(fw*ncols, fh*nrows),\n",
    "        sharex=False, sharey=True, constrained_layout=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # single colorbar\n",
    "    vmin, vmax = onp.quantile(quantities, q=clip_quantile), onp.quantile(quantities, q=(1-clip_quantile))\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax, clip=True)\n",
    "    mappable = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    mappable.set_array([])\n",
    "    cbar = fig.colorbar(mappable=mappable, norm=norm, ax=axs.ravel(), \n",
    "                        fraction=fraction, shrink=shrink, pad=pad,\n",
    "                        orientation='vertical')\n",
    "    cbar.set_label(title, fontsize=fontsize)\n",
    "    cbar.ax.tick_params(which='both', labelsize=fontsize, width=0, length=0)\n",
    "\n",
    "\n",
    "    # make scatter plot\n",
    "    for kk, ax in enumerate(axs):\n",
    "        # update basic visual aspects\n",
    "        cfg = data_dicts[v0s[kk]]['cfg']\n",
    "        ax.set_facecolor('k')\n",
    "        ax.set_xlim([-0.8*cfg.width, 0.8*cfg.width])\n",
    "        ax.set_ylim([-0.8*cfg.width, 0.8*cfg.width])\n",
    "        ax.set_xticks([-0.5*cfg.width, 0, 0.5*cfg.width],\n",
    "                      [r\"$-L/4$\", r\"$0.0$\", r\"$L/4$\"])\n",
    "        ax.set_yticks([-0.5*cfg.width, 0, 0.5*cfg.width],\n",
    "                      [r\"$-L/4$\", r\"$0.0$\", r\"$L/4$\"])\n",
    "        ax.set_title(titles[kk], fontsize=fontsize)\n",
    "        ax.axes.set_aspect(1.0)\n",
    "        ax.grid(which='both', axis='both', color='0.90', alpha=0.2)\n",
    "        ax.tick_params(axis='both', length=0, width=0, labelsize=fontsize)\n",
    "        s = radius_to_points(ax, 1.5)\n",
    "\n",
    "        # make plot\n",
    "        scat = ax.scatter(xs_plot[kk, :, 0], xs_plot[kk, :, 1], s=s, marker='o', c=quantities[kk], cmap=cmap, norm=norm)\n",
    "\n",
    "        if kk == 0:\n",
    "            ax.set_ylabel(r\"$y$\", fontsize=fontsize)\n",
    "        ax.set_xlabel(r\"$x$\", fontsize=fontsize)\n",
    "\n",
    "\n",
    "    if save_str != None:\n",
    "        fig.patch.set_facecolor('k')\n",
    "        fig.patch.set_alpha(0.0)\n",
    "        plt.savefig(f'{save_str}_particles.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps             = 4096*16\n",
    "SDE_trajs           = onp.array(compute_trajectories(n_steps=n_steps, start_index=0))\n",
    "skip                = 64\n",
    "particle_quantities = jax.device_put(\n",
    "    compute_particle_quantities(\n",
    "        batch_size=32, average_xgs=SDE_trajs[:, ::skip], ema_fac=0.9999\n",
    "    ), jax.devices('cpu')[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot individual quantity for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_index    = onp.random.randint(n_steps)\n",
    "npts_average  = 128\n",
    "clip_quantile = 0.05\n",
    "nv0s_plot     = 5\n",
    "\n",
    "make_particle_plot(\n",
    "    quantities=np.mean(particle_quantities['gdot'][:nv0s_plot, :npts_average], axis=1),\n",
    "    xs_plot=particle_quantities['xs'][:nv0s_plot, npts_average, :N],\n",
    "    normalize=True,\n",
    "    clip_quantile=clip_quantile,\n",
    "    title='',\n",
    "    save_str=''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over all quantities for figure saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_index   = 0\n",
    "npts_average = 128\n",
    "nv0s_plot    = 5\n",
    "\n",
    "\n",
    "titles = {\n",
    "    'gdot':   r\"$|v_g|$\",\n",
    "    'xdot':   r\"$|v_x|$\",\n",
    "    'v':      r\"$|v|$\", \n",
    "    'div_v':  r\"$\\nabla\\cdot v$\", \n",
    "    'div_vg': r\"$\\nabla_g\\cdot v_g$\", \n",
    "    'div_vx': r\"$\\nabla_x\\cdot v_x$\"\n",
    "}\n",
    "\n",
    "\n",
    "base_folder  = '/scratch/nb3397/results/mips/lowd_cates/figures/'\n",
    "date_folder  = '8_18_23'\n",
    "\n",
    "\n",
    "for key in particle_quantities.keys():\n",
    "    if key != 'xs':\n",
    "        make_particle_plot(\n",
    "            quantities=np.mean(particle_quantities[key][:nv0s_plot, :npts_average], axis=1),\n",
    "            xs_plot=particle_quantities['xs'][:nv0s_plot, plot_index, :, :],\n",
    "            normalize=True,\n",
    "            clip_quantile=0.05,\n",
    "            title=titles[key],\n",
    "            save_str=f'{base_folder}/{date_folder}/{key}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial gridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gridded_entropy_plot(\n",
    "    particle_quantities: np.ndarray,\n",
    "    particle_xs: np.ndarray,\n",
    "    batch_size: int,\n",
    "    npts_grid: int,\n",
    "    density_cutoff: float,\n",
    "    clip_quantile: float,\n",
    "    compute_density: bool,\n",
    "    map_to_particle: bool,\n",
    "    normalize: bool,\n",
    "    title: str,\n",
    "    save_str: str\n",
    ") -> None:\n",
    "    ## individual panels\n",
    "    titles = [rf\"$v_0={v0}$\" for v0 in v0s[:particle_quantities.shape[0]]]\n",
    "    nrows  = 1\n",
    "    ncols  = len(titles)\n",
    "    \n",
    "    ### bin the data\n",
    "    gridded_quantities       = onp.zeros((ncols, npts_grid, npts_grid))\n",
    "    xgrid_plots, ygrid_plots = onp.zeros((ncols, npts_grid, npts_grid)), onp.zeros((ncols, npts_grid, npts_grid))\n",
    "    xedges, yedges           = onp.zeros((ncols, npts_grid+1)), onp.zeros((ncols, npts_grid+1))\n",
    "    for kk in range(ncols):\n",
    "        gridded_quantities[kk], xedges[kk], yedges[kk] = np.histogram2d(\n",
    "            particle_xs[kk, :, :, 0].ravel(), particle_xs[kk, :, :, 1].ravel(), weights=particle_quantities[kk].ravel(), bins=npts_grid\n",
    "        )\n",
    "        \n",
    "        if compute_density:\n",
    "            multiplicity = onp.array(np.histogram2d(\n",
    "                particle_xs[kk, :, :, 0].ravel(), particle_xs[kk, :, :, 1].ravel(), bins=(xedges[kk], yedges[kk])\n",
    "            )[0])\n",
    "            \n",
    "            # remove noisy regions\n",
    "            multiplicity[multiplicity <= density_cutoff] = 1.0\n",
    "            gridded_quantities[kk][multiplicity <= density_cutoff] = 0.0\n",
    "            gridded_quantities[kk] /= multiplicity\n",
    "        else:\n",
    "            gridded_quantities[kk] /= particle_xs[kk, :, :, 0].size\n",
    "        \n",
    "        curr_xgrid, curr_ygrid = np.meshgrid(xedges[kk], yedges[kk], indexing='ij')\n",
    "        xgrid_plots[kk] = curr_xgrid[:-1, :-1] + 0.5*np.diff(xedges[kk])[:, None]\n",
    "        ygrid_plots[kk] = curr_ygrid[:-1, :-1] + 0.5*np.diff(yedges[kk])[None, :]\n",
    "\n",
    "\n",
    "    # normalize by v0\n",
    "    if normalize:\n",
    "        gridded_quantities[1:] = gridded_quantities[1:] / np.array(v0s)[1:gridded_quantities.shape[0], None, None]\n",
    "        title  = title + r\"$/v_0$\"\n",
    "\n",
    "\n",
    "    ### make figure\n",
    "    # common plot parameters\n",
    "    plt.close('all')\n",
    "    sns.set_palette('deep')\n",
    "    fw, fh    = 4, 5.5\n",
    "    fraction  = 0.15\n",
    "    pad       = 0.025\n",
    "    shrink    = 0.5\n",
    "    fontsize  = 21\n",
    "\n",
    "\n",
    "    # define the overall figure\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=nrows, ncols=ncols, figsize=(fw*ncols, fh*nrows),\n",
    "        sharex=False, sharey=True, constrained_layout=True\n",
    "    )\n",
    "    \n",
    "\n",
    "    ## single colorbar\n",
    "    cmap = sns.color_palette('mako', as_cmap=True)\n",
    "    vmin, vmax = onp.quantile(gridded_quantities, q=clip_quantile), onp.quantile(gridded_quantities, q=(1-clip_quantile))\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    mappable = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    mappable.set_array([])\n",
    "    cbar = fig.colorbar(mappable=mappable, ax=axs.ravel(), fraction=fraction,\n",
    "                        shrink=shrink, pad=pad, orientation='vertical')\n",
    "    cbar.ax.tick_params(which='both', labelsize=fontsize, width=0, length=0)\n",
    "    cbar.ax.yaxis.get_offset_text().set(size=0.8*fontsize)\n",
    "    cbar.set_label(title, fontsize=fontsize)\n",
    "    \n",
    "    ## manually clip to avoid weird background square artifact\n",
    "    gridded_quantities[gridded_quantities < vmin] = vmin\n",
    "    gridded_quantities[gridded_quantities > vmax] = vmax\n",
    "    gridded_quantities = np.array(gridded_quantities)\n",
    "\n",
    "\n",
    "    # make the actual plot\n",
    "    for kk, ax in enumerate(axs):\n",
    "        # set up simple plot parameters\n",
    "        cfg = data_dicts[v0s[kk]]['cfg']\n",
    "        ax.set_xlim([-cfg.width, cfg.width])\n",
    "        ax.set_ylim([-cfg.width, cfg.width])\n",
    "\n",
    "        ax.set_xticks([-0.5*cfg.width, 0, 0.5*cfg.width],\n",
    "                      [r\"$-L/4$\", r\"$0.0$\", r\"$L/4$\"])\n",
    "        ax.set_yticks([-0.5*cfg.width, 0, 0.5*cfg.width],\n",
    "                      [r\"$-L/4$\", r\"$0.0$\", r\"$L/4$\"])\n",
    "\n",
    "        ax.grid(which='both', axis='both', color='0.90', alpha=0.1)\n",
    "        ax.tick_params(which='both', width=0, length=0, labelsize=fontsize)\n",
    "        ax.axes.set_aspect(1.0)\n",
    "        ax.set_title(titles[kk], fontsize=fontsize)\n",
    "        ax.set_facecolor(mappable.to_rgba(0.0))\n",
    "\n",
    "\n",
    "        if kk == 0:\n",
    "            ax.set_ylabel(r\"$y$\", fontsize=fontsize)\n",
    "        ax.set_xlabel(r\"$x$\", fontsize=fontsize)\n",
    "\n",
    "\n",
    "        # make the plot\n",
    "        if map_to_particle:\n",
    "            particle_positions = particle_xs[kk, 0, :]\n",
    "            iis, jjs           = jax.vmap(grid_utils.find_grid_pt, in_axes=(0, None, None))(particle_positions, xedges[kk], yedges[kk])\n",
    "            particle_weights   = jax.vmap(lambda ii, jj: gridded_quantities[kk, ii, jj])(iis, jjs)\n",
    "            s                  = radius_to_points(ax, 1.5)\n",
    "            scat               = ax.scatter(particle_positions[:, 0], particle_positions[:, 1], s=s, marker='o', c=particle_weights, cmap=cmap, norm=norm)\n",
    "        else:\n",
    "            # plot real data\n",
    "            ctr = ax.contourf(xgrid_plots[kk], ygrid_plots[kk], gridded_quantities[kk], cmap=cmap, norm=norm, levels=100)\n",
    "\n",
    "            # fix strange aliasing artifact\n",
    "            for c in ctr.collections:\n",
    "                c.set_edgecolor(\"face\")\n",
    "                c.set_rasterized(True)\n",
    "\n",
    "\n",
    "    if save_str != None:\n",
    "        fig.patch.set_facecolor('k')\n",
    "        fig.patch.set_alpha(0.0)\n",
    "        if map_to_particle:\n",
    "            output_str = f'{save_str}_spatial_pp_on_particles'\n",
    "        else:\n",
    "            output_str = f'{save_str}_spatial_pp' if compute_density else f'{save_str}_spatial'\n",
    "        plt.savefig(f'{output_str}.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@functools.partial(jax.vmap, in_axes=(None, 0, None, None), out_axes=1)\n",
    "@functools.partial(jax.vmap, in_axes=(0, None, None, None), out_axes=0)\n",
    "def find_radial_values(\n",
    "    x: float,\n",
    "    y: float,\n",
    "    binned_quantity: np.ndarray,\n",
    "    redges: np.ndarray\n",
    ") -> float:\n",
    "    r  = np.sqrt(x**2 + y**2)\n",
    "    ii = np.argmax(redges > r) - 1\n",
    "    return binned_quantity[ii]\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "@functools.partial(jax.vmap, in_axes=(0, 0, 0), out_axes=0)\n",
    "@functools.partial(jax.vmap, in_axes=(0, None, None), out_axes=0)\n",
    "def find_radial_vec(\n",
    "    pos: np.ndarray,\n",
    "    binned_quantity: np.ndarray,\n",
    "    redges: np.ndarray\n",
    ") -> float:\n",
    "    r  = np.linalg.norm(pos)\n",
    "    ii = np.argmax(redges > r) - 1\n",
    "    return binned_quantity[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_radial_gridded_entropy_plot(\n",
    "    particle_quantities: np.ndarray,\n",
    "    particle_xs: np.ndarray,\n",
    "    batch_size: int,\n",
    "    npts_grid: int,\n",
    "    density_cutoff: float,\n",
    "    clip_quantile: float,\n",
    "    compute_density: bool,\n",
    "    map_to_particle: bool,\n",
    "    normalize: bool,\n",
    "    title: str,\n",
    "    save_str: str\n",
    ") -> None:\n",
    "    ## individual panels\n",
    "    nv0s   = particle_quantities.shape[0]\n",
    "    titles = [rf\"$v_0={v0}$\" for v0 in v0s[:nv0s]]\n",
    "    nrows  = 1\n",
    "    ncols  = nv0s\n",
    "\n",
    "\n",
    "    ## convert particle position data to radii\n",
    "    ntrajs              = particle_xs.shape[1]\n",
    "    particle_xs         = particle_xs.reshape((nv0s, -1, 2))\n",
    "    particle_quantities = particle_quantities.reshape((nv0s, -1))\n",
    "    particle_rs         = jax.vmap(jax.vmap(np.linalg.norm))(particle_xs)\n",
    "\n",
    "\n",
    "    ### bin the data radially and map to grid data\n",
    "    binned_quantities        = onp.zeros((ncols, npts_grid))\n",
    "    gridded_quantities       = onp.zeros((ncols, npts_grid, npts_grid))\n",
    "    xgrid_plots, ygrid_plots = onp.zeros((ncols, npts_grid, npts_grid)), onp.zeros((ncols, npts_grid, npts_grid))\n",
    "    redges                   = onp.zeros((ncols, npts_grid+1))\n",
    "    theta_bins               = onp.linspace(0.0, 2*onp.pi, npts_grid)\n",
    "    for kk in range(ncols):\n",
    "        binned_quantities[kk], redges[kk] = np.histogram(particle_rs[kk], weights=particle_quantities[kk], bins=npts_grid)\n",
    "\n",
    "        if compute_density:\n",
    "            multiplicity = onp.array(np.histogram(particle_rs[kk], bins=redges[kk])[0])\n",
    "\n",
    "            ### filter noisy regions\n",
    "            multiplicity[multiplicity <= density_cutoff] = 1.0\n",
    "            binned_quantities[kk][multiplicity <= density_cutoff] = 0.0\n",
    "            binned_quantities[kk] /= multiplicity\n",
    "        else:\n",
    "            ## probability of landing in a radial bin with radius r scales like r -- normalize.\n",
    "            rcenters               = redges[kk][:-1] + np.diff(redges[kk])\n",
    "            binned_quantities[kk]  = binned_quantities[kk] / rcenters\n",
    "            binned_quantities[kk] /= particle_rs[kk].size\n",
    "            \n",
    "        ## compute x and y grids to plot\n",
    "        rgrid, theta_grid      = np.meshgrid(redges[kk][:-1] + 0.5*np.diff(redges[kk]), theta_bins)\n",
    "        xgrid_plots[kk]        = rgrid*np.cos(theta_grid)\n",
    "        ygrid_plots[kk]        = rgrid*np.sin(theta_grid)\n",
    "        gridded_quantities[kk] = np.tile(binned_quantities[kk], (npts_grid, 1))\n",
    "\n",
    "\n",
    "    ### normalize by v0\n",
    "    if normalize:\n",
    "        gridded_quantities[1:] = gridded_quantities[1:] / onp.array(v0s)[1:nv0s, None, None]\n",
    "        title              = title + r\"$/v_0$\"\n",
    "    \n",
    "\n",
    "    ### compute particle mappings\n",
    "    if map_to_particle:\n",
    "        particle_positions = particle_xs.reshape((nv0s, -1, N, d))[:, onp.random.randint(ntrajs)]\n",
    "        particle_weights   = onp.array(find_radial_vec(particle_positions, np.array(binned_quantities), np.array(redges)))\n",
    "        \n",
    "        \n",
    "    ### compute colorbar\n",
    "    cmap = sns.color_palette('mako', as_cmap=True)\n",
    "    \n",
    "    if map_to_particle:\n",
    "        vmin, vmax = onp.quantile(particle_weights, q=clip_quantile), onp.quantile(particle_weights, q=(1-clip_quantile))\n",
    "    else:\n",
    "        vmin, vmax = onp.quantile(gridded_quantities, q=clip_quantile), onp.quantile(gridded_quantities, q=(1-clip_quantile))\n",
    "        \n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    mappable = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    mappable.set_array([])\n",
    "\n",
    "\n",
    "    ## manually clip to avoid weird background square artifact\n",
    "    if map_to_particle:\n",
    "        particle_weights[particle_weights < vmin] = vmin\n",
    "        particle_weights[particle_weights > vmax] = vmax\n",
    "    else:\n",
    "        gridded_quantities[gridded_quantities < vmin] = vmin\n",
    "        gridded_quantities[gridded_quantities > vmax] = vmax\n",
    "        gridded_quantities = np.array(gridded_quantities)\n",
    "        \n",
    "\n",
    "    ### make figure\n",
    "    # common plot parameters\n",
    "    plt.close('all')\n",
    "    sns.set_palette('deep')\n",
    "    fw, fh    = 4, 5.5\n",
    "    fraction  = 0.15\n",
    "    pad       = 0.025\n",
    "    shrink    = 0.5\n",
    "    fontsize  = 21\n",
    "\n",
    "\n",
    "    # define the overall figure\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=nrows, ncols=ncols, figsize=(fw*ncols, fh*nrows),\n",
    "        sharex=False, sharey=True, constrained_layout=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # make the actual plot\n",
    "    for kk, ax in enumerate(axs):        \n",
    "        # set up simple plot parameters\n",
    "        cfg = data_dicts[v0s[kk]]['cfg']\n",
    "        ax.set_xlim([-cfg.width, cfg.width])\n",
    "        ax.set_ylim([-cfg.width, cfg.width])\n",
    "\n",
    "        ax.set_xticks([-0.5*cfg.width, 0, 0.5*cfg.width],\n",
    "                      [r\"$-L/4$\", r\"$0.0$\", r\"$L/4$\"])\n",
    "        ax.set_yticks([-0.5*cfg.width, 0, 0.5*cfg.width],\n",
    "                      [r\"$-L/4$\", r\"$0.0$\", r\"$L/4$\"])\n",
    "\n",
    "        ax.grid(which='both', axis='both', color='0.90', alpha=0.1)\n",
    "        ax.tick_params(which='both', width=0, length=0, labelsize=fontsize)\n",
    "        ax.axes.set_aspect(1.0)\n",
    "        ax.set_title(titles[kk], fontsize=fontsize)\n",
    "        ax.set_facecolor(mappable.to_rgba(0.0))\n",
    "\n",
    "\n",
    "        if kk == 0:\n",
    "            ax.set_ylabel(r\"$y$\", fontsize=fontsize)\n",
    "        ax.set_xlabel(r\"$x$\", fontsize=fontsize)\n",
    "\n",
    "\n",
    "        # make the plot\n",
    "        if map_to_particle:\n",
    "            s    = radius_to_points(ax, 1.5)\n",
    "            scat = ax.scatter(particle_positions[kk, :, 0], particle_positions[kk, :, 1], \n",
    "                              s=s, marker='o', c=particle_weights[kk], \n",
    "                              cmap=cmap, norm=norm)\n",
    "        else:\n",
    "            ctr = ax.contourf(xgrid_plots[kk], ygrid_plots[kk], gridded_quantities[kk], cmap=cmap, norm=norm, levels=100)\n",
    "\n",
    "            # fix strange aliasing artifact\n",
    "            for c in ctr.collections:\n",
    "                c.set_edgecolor(\"face\")\n",
    "                c.set_rasterized(True)\n",
    "\n",
    "\n",
    "    cbar = fig.colorbar(mappable=mappable, norm=norm, ax=axs.ravel(), fraction=fraction, shrink=shrink, pad=pad, orientation='vertical')\n",
    "    cbar.ax.tick_params(which='both', labelsize=fontsize, width=0, length=0)\n",
    "    cbar.ax.yaxis.get_offset_text().set(size=0.8*fontsize)\n",
    "    cbar.set_label(title, fontsize=fontsize)\n",
    "\n",
    "\n",
    "    if save_str != None:\n",
    "        fig.patch.set_facecolor('k')\n",
    "        fig.patch.set_alpha(0.0)\n",
    "        output_str = f'{save_str}_radial_pp' if compute_density else f'{save_str}_radial'\n",
    "        plt.savefig(f'{output_str}.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute particle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pts_average = 4096*16\n",
    "# n_pts_average = 4096\n",
    "average_xgs   = onp.zeros((len(v0s), n_pts_average, 2*N, d))\n",
    "\n",
    "## pick points to average over\n",
    "for kk, v0 in enumerate(v0s):\n",
    "    curr_ntrajs     = data_dicts[v0]['xgs'].shape[0]\n",
    "    inds            = onp.random.choice(onp.arange(curr_ntrajs), size=n_pts_average, replace=True)\n",
    "    average_xgs[kk] = data_dicts[v0]['xgs'][inds]\n",
    "\n",
    "\n",
    "particle_quantities_grid = compute_particle_quantities(\n",
    "    batch_size=32, average_xgs=average_xgs, ema_fac=0.9999\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot individual quantity for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv0s_plot = 5\n",
    "\n",
    "\n",
    "make_radial_gridded_entropy_plot(\n",
    "    particle_quantities_grid['gdot'][:nv0s_plot],\n",
    "    particle_quantities_grid['xs'][:nv0s_plot],\n",
    "    batch_size=256,\n",
    "    npts_grid=128,\n",
    "    density_cutoff=25,\n",
    "    clip_quantile=0.1,\n",
    "    normalize=True,\n",
    "    map_to_particle=False,\n",
    "    compute_density=True,\n",
    "    title='',\n",
    "    save_str=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv0s_plot = 5\n",
    "\n",
    "\n",
    "make_radial_gridded_entropy_plot(\n",
    "    particle_quantities_grid['gdot'][:nv0s_plot],\n",
    "    particle_quantities_grid['xs'][:nv0s_plot],\n",
    "    batch_size=256,\n",
    "    npts_grid=128,\n",
    "    density_cutoff=5,\n",
    "    clip_quantile=0.05,\n",
    "    normalize=True,\n",
    "    map_to_particle=True,\n",
    "    compute_density=True,\n",
    "    title='',\n",
    "    save_str=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv0s_plot = 5\n",
    "\n",
    "\n",
    "make_radial_gridded_entropy_plot(\n",
    "    particle_quantities_grid['gdot'][:nv0s_plot],\n",
    "    particle_quantities_grid['xs'][:nv0s_plot],\n",
    "    batch_size=256,\n",
    "    npts_grid=128,\n",
    "    density_cutoff=25,\n",
    "    clip_quantile=0.05,\n",
    "    normalize=True,\n",
    "    map_to_particle=False,\n",
    "    compute_density=False,\n",
    "    title='',\n",
    "    save_str=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv0s_plot = 5\n",
    "\n",
    "\n",
    "make_gridded_entropy_plot(\n",
    "    particle_quantities_grid['div_v'][:nv0s_plot],\n",
    "    particle_quantities_grid['xs'][:nv0s_plot],\n",
    "    batch_size=256,\n",
    "    npts_grid=128,\n",
    "    density_cutoff=0,\n",
    "    clip_quantile=0,\n",
    "    normalize=True,\n",
    "    map_to_particle=False,\n",
    "    compute_density=False,\n",
    "    title='',\n",
    "    save_str=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv0s_plot = 5\n",
    "\n",
    "\n",
    "make_gridded_entropy_plot(\n",
    "    particle_quantities_grid['div_v'][:nv0s_plot],\n",
    "    particle_quantities_grid['xs'][:nv0s_plot],\n",
    "    batch_size=256,\n",
    "    npts_grid=128,\n",
    "    density_cutoff=10,\n",
    "    clip_quantile=0.01,\n",
    "    normalize=True,\n",
    "    map_to_particle=False,\n",
    "    compute_density=True,\n",
    "    title='',\n",
    "    save_str=''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make all Cartesian grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {\n",
    "    'gdot':   r\"$|v_g|$\",\n",
    "    'xdot':   r\"$|v_x|$\",\n",
    "    'v':      r\"$|v|$\", \n",
    "    'div_v':  r\"$\\nabla\\cdot v$\", \n",
    "    'div_vg': r\"$\\nabla_g\\cdot v_g$\", \n",
    "    'div_vx': r\"$\\nabla_x\\cdot v_x$\"\n",
    "}\n",
    "\n",
    "nv0s_plot    = 5\n",
    "base_folder  = '/scratch/nb3397/results/mips/lowd_cates/figures/'\n",
    "date_folder  = '8_18_23'\n",
    "\n",
    "\n",
    "for key in particle_quantities_grid.keys():\n",
    "    if key != 'xs':\n",
    "        for compute_density in [True, False]:\n",
    "            for map_to_particle in [True, False]:\n",
    "                if map_to_particle and not compute_density:\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f'Starting {key} with compute_density={compute_density} and map_to_particle={map_to_particle}')\n",
    "                    make_gridded_entropy_plot(\n",
    "                        particle_quantities_grid[key][:nv0s_plot],\n",
    "                        particle_quantities_grid['xs'][:nv0s_plot],\n",
    "                        batch_size=256,\n",
    "                        npts_grid=128,\n",
    "                        density_cutoff=5,\n",
    "                        normalize=True,\n",
    "                        clip_quantile=0.025,\n",
    "                        compute_density=compute_density,\n",
    "                        map_to_particle=map_to_particle,\n",
    "                        title=titles[key],\n",
    "                        save_str=f'{base_folder}/{date_folder}/{key}'\n",
    "                    )\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make all radial grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {\n",
    "    'gdot':   r\"$|v_g|$\",\n",
    "    'xdot':   r\"$|v_x|$\",\n",
    "    'v':      r\"$|v|$\", \n",
    "    'div_v':  r\"$\\nabla\\cdot v$\", \n",
    "    'div_vg': r\"$\\nabla_g\\cdot v_g$\", \n",
    "    'div_vx': r\"$\\nabla_x\\cdot v_x$\"\n",
    "}\n",
    "\n",
    "nv0s_plot    = 5\n",
    "base_folder  = '/scratch/nb3397/results/mips/lowd_cates/figures/'\n",
    "date_folder  = '8_18_23'\n",
    "\n",
    "\n",
    "for key in particle_quantities_grid.keys():\n",
    "    if key != 'xs':\n",
    "        for compute_density in [True, False]:\n",
    "            print(f'Starting {key} with compute_density={compute_density} and map_to_particle={map_to_particle}')\n",
    "            make_radial_gridded_entropy_plot(\n",
    "                particle_quantities_grid[key][:nv0s_plot],\n",
    "                particle_quantities_grid['xs'][:nv0s_plot],\n",
    "                batch_size=256,\n",
    "                npts_grid=256,\n",
    "                density_cutoff=10,\n",
    "                normalize=True,\n",
    "                clip_quantile=0.025,\n",
    "                compute_density=compute_density,\n",
    "                map_to_particle=map_to_particle,\n",
    "                title=titles[key],\n",
    "                save_str=f'{base_folder}/{date_folder}/{key}'\n",
    "            )\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Radial + Particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_radial_gridded_and_particle_combined_entropy_plot(\n",
    "    particle_quantities_grid: np.ndarray,\n",
    "    particle_grid_xs: np.ndarray,\n",
    "    particle_quantities: np.ndarray,\n",
    "    particle_xs: np.ndarray,\n",
    "    batch_size: int,\n",
    "    npts_grid: int,\n",
    "    density_cutoff: float,\n",
    "    clip_quantile: float,\n",
    "    colormap_str: str,\n",
    "    radial: bool,\n",
    "    particle_colorbar: bool,\n",
    "    map_to_particle: bool,\n",
    "    title: str,\n",
    "    save_str: str\n",
    ") -> None:\n",
    "    ##### define figure and axes\n",
    "    plt.close('all')\n",
    "    sns.set_palette('deep')\n",
    "    fw, fh    = 4, 4\n",
    "\n",
    "\n",
    "    if particle_colorbar:\n",
    "        fraction  = 0.15\n",
    "        pad       = 0.025\n",
    "        shrink    = 0.75\n",
    "    else:\n",
    "        fraction  = 0.15\n",
    "        pad       = 0.025\n",
    "        shrink    = 0.5\n",
    "\n",
    "\n",
    "    fontsize  = 21\n",
    "    nv0s      = particle_quantities_grid.shape[0]\n",
    "    titles    = [rf\"$v_0={v0}$\" for v0 in v0s[:nv0s]]\n",
    "    nrows     = 2\n",
    "    ncols     = nv0s\n",
    "    title     = title + r\"$/v_0$\"\n",
    "    cmap      = sns.color_palette(colormap_str, as_cmap=True)\n",
    "    fig, axs  = plt.subplots(\n",
    "        nrows=nrows, ncols=ncols, figsize=(fw*ncols, fh*nrows),\n",
    "        sharex=True, sharey=True, constrained_layout=True\n",
    "    )\n",
    "\n",
    "\n",
    "    ## basic properties common to all axes\n",
    "    cfg = data_dicts[v0s[0]]['cfg']\n",
    "    for ax in axs.ravel():\n",
    "        ax.set_xlim([-cfg.width, cfg.width])\n",
    "        ax.set_ylim([-cfg.width, cfg.width])\n",
    "        ax.grid(which='both', axis='both', color='0.90', alpha=0.1)\n",
    "        ax.tick_params(which='both', width=0, length=0, labelsize=fontsize)\n",
    "        ax.axes.set_aspect(1.0)\n",
    "        ax.set_xticks([-0.5*cfg.width, 0, 0.5*cfg.width],\n",
    "                      [r\"$-L/4$\", r\"$0.0$\", r\"$L/4$\"])\n",
    "        ax.set_yticks([-0.5*cfg.width, 0, 0.5*cfg.width],\n",
    "                      [r\"$-L/4$\", r\"$0.0$\", r\"$L/4$\"])\n",
    "\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "             spine.set_edgecolor('black')\n",
    "\n",
    "\n",
    "    ######### radially-filtered grid #########\n",
    "    ## convert particle position data to radii\n",
    "    ntrajs                   = particle_grid_xs.shape[1]\n",
    "    particle_grid_xs         = particle_grid_xs.reshape((nv0s, -1, 2))\n",
    "    particle_quantities_grid = particle_quantities_grid.reshape((nv0s, -1))\n",
    "    particle_rs              = jax.vmap(jax.vmap(np.linalg.norm))(particle_grid_xs)\n",
    "\n",
    "\n",
    "    ### bin the data and map to grid data\n",
    "    gridded_quantities       = onp.zeros((ncols, npts_grid, npts_grid))\n",
    "    xgrid_plots, ygrid_plots = onp.zeros((ncols, npts_grid, npts_grid)), onp.zeros((ncols, npts_grid, npts_grid))\n",
    "    if radial:\n",
    "        binned_quantities = onp.zeros((ncols, npts_grid))\n",
    "        redges            = onp.zeros((ncols, npts_grid+1))\n",
    "        theta_edges       = np.linspace(0.0, 2*np.pi, npts_grid)\n",
    "        for kk in range(ncols):\n",
    "            ## radially bin\n",
    "            binned_quantities[kk], redges[kk] = np.histogram(particle_rs[kk], weights=particle_quantities_grid[kk], bins=npts_grid)\n",
    "            multiplicity                      = onp.array(np.histogram(particle_rs[kk], bins=redges[kk])[0])\n",
    "            rcenters                          = redges[kk, :-1] + 0.5*np.diff(redges[kk])\n",
    "\n",
    "            ## filter out noisy regions\n",
    "            inds                         = (multiplicity / rcenters) <= density_cutoff\n",
    "            multiplicity[inds]           = 1.0\n",
    "            binned_quantities[kk][inds]  = 0.0\n",
    "            binned_quantities[kk]       /= multiplicity\n",
    "\n",
    "            ## compute x and y grids to plot\n",
    "            rgrid, theta_grid      = np.meshgrid(redges[kk][:-1] + 0.5*np.diff(redges[kk]), theta_edges)\n",
    "            xgrid_plots[kk]        = rgrid*np.cos(theta_grid)\n",
    "            ygrid_plots[kk]        = rgrid*np.sin(theta_grid)\n",
    "            gridded_quantities[kk] = np.tile(binned_quantities[kk], (npts_grid, 1))\n",
    "    else:\n",
    "        xedges, yedges           = onp.zeros((ncols, npts_grid+1)), onp.zeros((ncols, npts_grid+1))\n",
    "        for kk in range(ncols):\n",
    "            ## cartesian bin\n",
    "            gridded_quantities[kk], xedges[kk], yedges[kk] = np.histogram2d(\n",
    "                particle_grid_xs[kk, :, 0], particle_grid_xs[kk, :, 1], weights=particle_quantities_grid[kk], bins=npts_grid\n",
    "            )\n",
    "            \n",
    "            multiplicity = onp.array(\n",
    "                np.histogram2d(particle_grid_xs[kk, :, 0], particle_grid_xs[kk, :, 1], bins=(xedges[kk], yedges[kk]))[0]\n",
    "            )\n",
    "\n",
    "            ## filter out noisy regions\n",
    "            multiplicity[multiplicity <= density_cutoff] = 1.0\n",
    "            gridded_quantities[kk][multiplicity <= density_cutoff] = 0.0\n",
    "            gridded_quantities[kk] /= multiplicity\n",
    "            curr_xgrid, curr_ygrid = np.meshgrid(xedges[kk], yedges[kk], indexing='ij')\n",
    "            xgrid_plots[kk] = curr_xgrid[:-1, :-1] + 0.5*np.diff(xedges[kk])[:, None]\n",
    "            ygrid_plots[kk] = curr_ygrid[:-1, :-1] + 0.5*np.diff(yedges[kk])[None, :]\n",
    "\n",
    "\n",
    "    ## normalize and compute colorbar\n",
    "    gridded_quantities[1:] = gridded_quantities[1:] / onp.array(v0s)[1:nv0s, None, None]\n",
    "    vmin, vmax = onp.quantile(gridded_quantities, q=clip_quantile), onp.quantile(gridded_quantities, q=(1-clip_quantile))\n",
    "    norm       = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    mappable   = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    mappable.set_array([])\n",
    "\n",
    "\n",
    "    ## manually clip to avoid weird background square artifact\n",
    "    gridded_quantities[gridded_quantities < vmin] = vmin\n",
    "    gridded_quantities[gridded_quantities > vmax] = vmax\n",
    "    gridded_quantities = np.array(gridded_quantities)\n",
    "\n",
    "\n",
    "    ## make the actual plot\n",
    "    for kk, ax in enumerate(axs[1]):        \n",
    "        # set up simple plot parameters\n",
    "        cfg = data_dicts[v0s[kk]]['cfg']\n",
    "        ax.set_xlabel(r\"$x$\", fontsize=fontsize)\n",
    "        ax.set_facecolor(mappable.to_rgba(0.0))\n",
    "\n",
    "        if kk == 0:\n",
    "            ax.set_ylabel(r\"$y$\", fontsize=fontsize)\n",
    "\n",
    "        # make the plot\n",
    "        ctr = ax.contourf(xgrid_plots[kk], ygrid_plots[kk], gridded_quantities[kk], cmap=cmap, norm=norm, levels=100)\n",
    "\n",
    "        # fix strange aliasing artifact\n",
    "        for c in ctr.collections:\n",
    "            c.set_edgecolor(\"face\")\n",
    "            c.set_rasterized(True)\n",
    "\n",
    "\n",
    "    ######## plot particle realization ########\n",
    "    if map_to_particle:\n",
    "        if radial:\n",
    "            particle_xs         = particle_grid_xs.reshape((nv0s, -1, N, d))[:, onp.random.randint(ntrajs)]\n",
    "            particle_quantities = onp.array(find_radial_vec(particle_xs, np.array(binned_quantities), np.array(redges)))\n",
    "        else:\n",
    "            particle_xs        = particle_grid_xs.reshape((nv0s, -1, N, d))[:, onp.random.randint(ntrajs)]\n",
    "            print(xedges.shape, yedges.shape)\n",
    "\n",
    "            # map over all particles and all values of v0\n",
    "            iis, jjs            = jax.vmap(\n",
    "                jax.vmap(grid_utils.find_grid_pt, in_axes=(0, None, None))\n",
    "            )(particle_xs, xedges, yedges)\n",
    "            particle_quantities = onp.array(\n",
    "                jax.vmap(\n",
    "                    jax.vmap(\n",
    "                        lambda ii, jj, grid_quantity: grid_quantity[ii, jj],\n",
    "                        in_axes=(0, 0, None)\n",
    "                    )\n",
    "                )(iis, jjs, gridded_quantities)\n",
    "            )\n",
    "\n",
    "    ## normalize if it wasn't done already\n",
    "    particle_quantities         = onp.array(particle_quantities)\n",
    "    if not map_to_particle:\n",
    "        particle_quantities[1:nv0s] = particle_quantities[1:nv0s] / (np.array(v0s)[1:nv0s])[:, None]\n",
    "\n",
    "    if particle_colorbar:\n",
    "        vmin, vmax = onp.quantile(particle_quantities, q=clip_quantile), onp.quantile(particle_quantities, q=(1-clip_quantile))\n",
    "        particle_norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "        particle_mappable = mpl.cm.ScalarMappable(cmap=cmap, norm=particle_norm)\n",
    "        particle_mappable.set_array([])\n",
    "\n",
    "    ## manually clip to colorbar\n",
    "    particle_quantities[particle_quantities < vmin] = vmin\n",
    "    particle_quantities[particle_quantities > vmax] = vmax\n",
    "\n",
    "\n",
    "    for kk, ax in enumerate(axs[0]):\n",
    "        ax.set_title(titles[kk], fontsize=fontsize)\n",
    "        ax.set_facecolor(mappable.to_rgba(0.0))\n",
    "        cfg  = data_dicts[v0s[kk]]['cfg']\n",
    "        s    = radius_to_points(ax, 1.5)\n",
    "        scat = ax.scatter(particle_xs[kk, :, 0], particle_xs[kk, :, 1], \n",
    "                          s=s, marker='o', c=particle_quantities[kk], \n",
    "                          cmap=cmap, norm=(particle_norm if particle_colorbar else norm))\n",
    "\n",
    "\n",
    "        if kk == 0:\n",
    "            ax.set_ylabel(r\"$y$\", fontsize=fontsize)\n",
    "\n",
    "    ### construct the shared colorbar\n",
    "    if particle_colorbar:\n",
    "        for kk, (curr_mappable, curr_norm) in enumerate(\n",
    "            zip([mappable, particle_mappable], [particle_norm, particle_mappable])\n",
    "        ):\n",
    "            cbar = fig.colorbar(mappable=curr_mappable, norm=curr_norm, ax=axs[kk].ravel(), fraction=fraction, shrink=shrink, pad=pad, orientation='vertical')\n",
    "            cbar.ax.tick_params(which='both', labelsize=fontsize, width=0, length=0)\n",
    "            cbar.ax.yaxis.get_offset_text().set(size=0.8*fontsize)\n",
    "            cbar.set_label(title, fontsize=fontsize)\n",
    "            cbar.outline.set_edgecolor('grey')\n",
    "    else:\n",
    "        cbar = fig.colorbar(mappable=mappable, norm=norm, ax=axs.ravel(), fraction=fraction, shrink=shrink, pad=pad, orientation='vertical')\n",
    "        cbar.ax.tick_params(which='both', labelsize=fontsize, width=0, length=0)\n",
    "        cbar.ax.yaxis.get_offset_text().set(size=0.8*fontsize)\n",
    "        cbar.set_label(title, fontsize=fontsize)\n",
    "        cbar.outline.set_edgecolor('grey')\n",
    "\n",
    "\n",
    "    if save_str != '':\n",
    "        fig.patch.set_facecolor('k')\n",
    "        fig.patch.set_alpha(0.0)\n",
    "\n",
    "        base_str = f'{save_str}_combined'\n",
    "        if radial:\n",
    "            base_str += '_radial'\n",
    "        if map_to_particle:\n",
    "            base_str += '_on_particle'\n",
    "        if particle_colorbar:\n",
    "            base_str += '_particle_colorbar'\n",
    "\n",
    "        plt.savefig(f'{base_str}.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv0s     = 5\n",
    "quantity = 'div_vx'\n",
    "npts_avg = 128\n",
    "\n",
    "\n",
    "make_radial_gridded_and_particle_combined_entropy_plot(\n",
    "    particle_quantities_grid[quantity][:nv0s],\n",
    "    particle_quantities_grid['xs'][:nv0s],\n",
    "    np.median(particle_quantities[quantity][:nv0s, :npts_avg], axis=1),\n",
    "    particle_quantities['xs'][:nv0s, npts_avg],\n",
    "    batch_size=256,\n",
    "    npts_grid=64,\n",
    "    density_cutoff=10,\n",
    "    clip_quantile=0.05,\n",
    "    colormap_str='mako',\n",
    "    particle_colorbar=False,\n",
    "    map_to_particle=True,\n",
    "    radial=True,\n",
    "    title='',\n",
    "    save_str=''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {\n",
    "    'gdot':   r\"$|v_g|$\",\n",
    "    'xdot':   r\"$|v_x|$\",\n",
    "    'v':      r\"$|v|$\", \n",
    "    'div_v':  r\"$\\nabla\\cdot v$\", \n",
    "    'div_vg': r\"$\\nabla_g\\cdot v_g$\", \n",
    "    'div_vx': r\"$\\nabla_x\\cdot v_x$\"\n",
    "}\n",
    "\n",
    "\n",
    "nv0s_plot    = 5\n",
    "npts_avg     = 128\n",
    "base_folder  = '/scratch/nb3397/results/mips/lowd_cates/figures/'\n",
    "# date_folder  = '8_18_23'\n",
    "date_folder  = '9_16_23'\n",
    "\n",
    "\n",
    "for key in titles.keys():\n",
    "    for particle_colorbar in [True, False]:\n",
    "        for map_to_particle in [True, False]:\n",
    "            print(f'Starting {key}!')\n",
    "            make_radial_gridded_and_particle_combined_entropy_plot(\n",
    "                particle_quantities_grid[key][:nv0s_plot],\n",
    "                particle_quantities_grid['xs'][:nv0s_plot],\n",
    "                np.median(particle_quantities[key][:nv0s_plot, :npts_avg], axis=1),\n",
    "                particle_quantities['xs'][:nv0s_plot, npts_avg],\n",
    "                batch_size=256,\n",
    "                npts_grid=128,\n",
    "                density_cutoff=5,\n",
    "                clip_quantile=0.05,\n",
    "                colormap_str='mako',\n",
    "                particle_colorbar=particle_colorbar,\n",
    "                map_to_particle=map_to_particle,\n",
    "                radial=False,\n",
    "                title=titles[key],\n",
    "                save_str=f'{base_folder}/{date_folder}/{key}'\n",
    "            )\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnums=(2, 3, 4))\n",
    "@functools.partial(jax.vmap, in_axes=(0, None, None, None, None))\n",
    "def compute_batch_statistics(\n",
    "    xgs: np.ndarray,\n",
    "    params: Dict[str, hk.Params],\n",
    "    cfg: config_dict.ConfigDict,\n",
    "    score_net: Callable,\n",
    "    particle_div_net: Callable,\n",
    ") -> Tuple:\n",
    "    \"\"\"Compute the quantitative verification metrics over a batch.\"\"\"\n",
    "    xs, gs = np.split(xgs, 2)                        # ([N, d], [N, d])\n",
    "    sxs = score_net.apply(params['x'], xs, gs, 'x')  # [N, d]\n",
    "    sgs = score_net.apply(params['g'], xs, gs, 'g')  # [N, d]\n",
    "    particle_scores = np.hstack((sxs, sgs))          # [N, 2*d]\n",
    "    vs = launcher.calc_vs(xgs, sxs, sgs, cfg)[-1]    # (N, 2d)\n",
    "    div_sxs, div_sgs, div_vxs, div_vgs, div_vs = \\\n",
    "        launcher.calc_divs(params, xs, gs, cfg, particle_div_net) # ([N], [N], [N], [N], [N])\n",
    "\n",
    "    div_v     = np.sum(div_vs)\n",
    "    div_vx    = np.sum(div_vxs)\n",
    "    div_vg    = np.sum(div_vgs)\n",
    "    v_times_s = np.sum(vs*particle_scores)\n",
    "    pinn      = div_v + v_times_s\n",
    "    ibp       = np.sum(particle_scores**2) + np.sum(div_sxs + div_sgs)\n",
    "\n",
    "    return div_v, div_vx, div_vg, v_times_s, ibp, pinn\n",
    "\n",
    "\n",
    "def compute_statistics(\n",
    "    batch_size: int,\n",
    "    n_samples: int,\n",
    "    ema_fac: float\n",
    ") -> dict:\n",
    "    \"\"\"Compute the quantitative verification metrics.\"\"\"\n",
    "    ## pick time samples for averaging and set up batching\n",
    "    ntrajs = data_dicts[v0s[-1]]['xgs'].shape[0]\n",
    "    inds = onp.random.choice(onp.arange(ntrajs), size=n_samples)\n",
    "    if n_samples % batch_size == 0:\n",
    "        n_batches = n_samples // batch_size\n",
    "    else:   \n",
    "        n_batches = int(n_samples / batch_size) + 1\n",
    "\n",
    "\n",
    "    ## set up arrays to hold statistics of interest\n",
    "    n_v0s = len(v0s)\n",
    "    statistics = {\n",
    "        'div_v':     onp.zeros((n_v0s, n_samples)),\n",
    "        'div_vx':    onp.zeros((n_v0s, n_samples)),\n",
    "        'div_vg':    onp.zeros((n_v0s, n_samples)),\n",
    "        'v_times_s': onp.zeros((n_v0s, n_samples)),\n",
    "        'ibp':       onp.zeros((n_v0s, n_samples)),\n",
    "        'pinn':      onp.zeros((n_v0s, n_samples)),\n",
    "    }\n",
    "\n",
    "\n",
    "    for kk, v0 in enumerate(v0s):\n",
    "        # unpack everything\n",
    "        data_dict   = data_dicts[v0]\n",
    "        cfg         = make_cfg_hashable(data_dict['cfg'])\n",
    "        params      = get_params(data_dict, ema_fac)\n",
    "        xgs         = data_dict['xgs'][inds]\n",
    "        xs, gs      = np.split(xgs, 2, axis=1)\n",
    "\n",
    "        # set up needed functions\n",
    "        score_net, particle_div_net, _, _ = launcher.construct_network(cfg)\n",
    "\n",
    "        # compute quantity of interest for spatial averaging\n",
    "        for curr_batch in range(n_batches):\n",
    "            start_time = time.time()\n",
    "            lb = curr_batch*batch_size\n",
    "            ub = lb + batch_size\n",
    "            \n",
    "            statistics['div_v'][kk, lb:ub], \\\n",
    "            statistics['div_vx'][kk, lb:ub], \\\n",
    "            statistics['div_vg'][kk, lb:ub], \\\n",
    "            statistics['v_times_s'][kk, lb:ub], \\\n",
    "            statistics['ibp'][kk, lb:ub:], \\\n",
    "            statistics['pinn'][kk, lb:ub] = compute_batch_statistics(xgs[lb:ub], params, cfg, score_net, particle_div_net)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            print(f'[{curr_batch+1}/{n_batches}], [{kk+1}/{len(v0s)}], {end_time-start_time}s. ')\n",
    "\n",
    "    return statistics\n",
    "\n",
    "\n",
    "def make_histogram_plot(\n",
    "    statistics: np.ndarray,\n",
    "    v0s_plot: list,\n",
    "    bins: int,\n",
    "    sup_title: str,\n",
    "    save_str: str\n",
    ") -> None:\n",
    "    ## make the figure\n",
    "    plt.close('all')\n",
    "    fw, fh    = 4, 4\n",
    "    fontsize  = 22\n",
    "    titles    = [rf\"$v_0=${v0}\" for v0 in v0s_plot]\n",
    "    nv0s_plot = len(v0s_plot)\n",
    "\n",
    "\n",
    "    with sns.axes_style('whitegrid'), plt.rc_context(rc={'text.usetex': True, 'font.family': 'serif'}):\n",
    "        cmap = sns.cubehelix_palette(n_colors=6)\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=nv0s_plot, sharey=True, constrained_layout=True, figsize=(nv0s_plot*fw, fh))\n",
    "        fig.suptitle(sup_title, fontsize=fontsize)\n",
    "\n",
    "\n",
    "        for kk, ax in enumerate(axs):\n",
    "            ax.grid(which='both', axis='both', color='0.75', alpha=0.5)\n",
    "            ax.tick_params(axis='both', labelsize=fontsize)\n",
    "            ax.hist(statistics[kk] / (2*N*d), bins=bins, color=cmap[kk])\n",
    "            ax.set_title(titles[kk], fontsize=fontsize)\n",
    "            ax.xaxis.offsetText.set_fontsize(0.8*fontsize)\n",
    "            mean, std = np.mean(statistics[kk] / (2*N*d)) , np.std(statistics[kk] / (2*N*d))\n",
    "            ax.axvline(mean,     color='k',          alpha=0.25)\n",
    "            ax.text(0.05, 0.9, rf\"$\\mu={mean:.1e}$\",   transform=ax.transAxes, fontsize=0.65*fontsize)\n",
    "            ax.text(0.65, 0.9, rf\"$\\sigma={std:.1e}$\", transform=ax.transAxes, fontsize=0.65*fontsize)\n",
    "\n",
    "\n",
    "            if kk == 0:\n",
    "                ax.set_ylabel('count', fontsize=fontsize)\n",
    "\n",
    "        if save_str != '':\n",
    "            fig.patch.set_facecolor('k')\n",
    "            fig.patch.set_alpha(0.0)\n",
    "            fig.savefig(save_str, dpi=300, bbox_inches='tight', facecolor=fig.get_facecolor())\n",
    "        else:\n",
    "            # shouldn't need this, but seems that we do anyways for some reason.\n",
    "            # moreover, it seems to save only a white figure if we do this outside the else block.\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = compute_statistics(batch_size=64, n_samples=4096*16, ema_fac=0.9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv0s_plot = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_histogram_plot(statistics['pinn'][:nv0s_plot], v0s_plot=v0s[:nv0s_plot], bins=50, sup_title='', save_str='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_histogram_plot(statistics['div_v'][:nv0s_plot], v0s_plot=v0s[:nv0s_plot], bins=50, sup_title='', save_str='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_histogram_plot(statistics['ibp'][:nv0s_plot], v0s_plot=v0s[:nv0s_plot], bins=50, sup_title='', save_str='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_histogram_plot(statistics['v_times_s'][:nv0s_plot], v0s_plot=v0s[:nv0s_plot], bins=50, sup_title='', save_str='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loop and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv0s_plot = 5\n",
    "\n",
    "titles = {\n",
    "    'div_v':     r\"$\\nabla\\cdot v$\",\n",
    "    'v_times_s': r\"$v\\cdot h$\",\n",
    "    'ibp':       r\"$|h|^2 + \\nabla \\cdot h$\",\n",
    "    'pinn':      r\"$\\nabla\\cdot v + v\\cdot h$\"\n",
    "}\n",
    "\n",
    "# base_output_folder = '/scratch/nb3397/results/mips/lowd_cates/figures/8_18_23'\n",
    "base_output_folder = '/scratch/nb3397/results/mips/lowd_cates/figures/9_20_23'\n",
    "\n",
    "\n",
    "for key in titles.keys():\n",
    "    make_histogram_plot(statistics[key][:nv0s_plot], v0s_plot=v0s[:nv0s_plot], \n",
    "                        bins=50, sup_title=titles[key], \n",
    "                        save_str=f'{base_output_folder}/{key}_statistics.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Flow Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rollout functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pflow_rhs(\n",
    "    xgs: np.ndarray, # [2N, d]\n",
    "    score_net: Callable,\n",
    "    cfg: config_dict.FrozenConfigDict,\n",
    "    params: Dict[str, hk.Params]\n",
    ") -> np.ndarray:\n",
    "    xs, gs = np.split(xgs, 2) # [N, d], [N, d]\n",
    "    xdots  = launcher.calc_xdots(xgs, cfg) - cfg.eps*score_net.apply(params['x'], xs, gs, 'x')\n",
    "    gdots  = -cfg.gamma*gs - cfg.gamma*score_net.apply(params['g'], xs, gs, 'g')\n",
    "    return np.concatenate((xdots, gdots))\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnums=(1, 2))\n",
    "def step_pflow(\n",
    "    xgs: np.ndarray, # [2N, d]\n",
    "    score_net: Callable,\n",
    "    cfg: config_dict.FrozenConfigDict,\n",
    "    params: Dict[str, hk.Params],\n",
    "    dt: float,\n",
    ") -> np.ndarray:\n",
    "    xs, gs       = np.split(xgs, 2)\n",
    "    xdots, gdots = np.split(pflow_rhs(xgs, score_net, cfg, params), 2)\n",
    "    xnexts       = drifts.torus_project(xs + dt*xdots, cfg.width)\n",
    "    gnexts       = gs + dt*gdots\n",
    "    return np.concatenate((xnexts, gnexts))\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnums=(2, 3))\n",
    "def rollout_traj_pflow(\n",
    "    init_xgs: np.ndarray, # [2N, d]\n",
    "    steps: np.ndarray,    # [nsteps]\n",
    "    score_net: Callable,\n",
    "    cfg: config_dict.FrozenConfigDict,\n",
    "    params: Dict[str, hk.Params],\n",
    "    dt: float,\n",
    ") -> np.ndarray:\n",
    "    def scan_fn(xgs: np.ndarray, step: np.ndarray):\n",
    "        xgsnext = step_pflow(xgs, score_net, cfg, params, dt)\n",
    "        return xgsnext, xgsnext\n",
    "\n",
    "    xgs_final, xgs_traj = jax.lax.scan(scan_fn, init_xgs, steps)\n",
    "    return xgs_traj\n",
    "\n",
    "\n",
    "def compute_pflow_trajs(\n",
    "    tf: int,\n",
    "    nbatches: int,\n",
    "    ema_fac: float,\n",
    "    dt: float\n",
    ") -> onp.ndarray:\n",
    "    \"\"\"Compute a probability flow trajectory for each value of v0.\"\"\"\n",
    "    # select random initialization for each value of v0\n",
    "    init_index = onp.random.randint(data_dicts[v0s[-1]]['xgs'].shape[0])\n",
    "    \n",
    "    ## set up arrays for storing trajectories\n",
    "    n_v0s  = len(v0s)\n",
    "    nsteps = int(tf / dt)\n",
    "    bs     = nsteps // nbatches\n",
    "    assert nsteps % nbatches == 0\n",
    "    trajs  = onp.zeros((n_v0s, nsteps+1, 2*N, d))\n",
    "\n",
    "    for kk, v0 in enumerate(v0s):        \n",
    "        # unpack everything\n",
    "        data_dict    = data_dicts[v0]\n",
    "        cfg          = make_cfg_hashable(data_dict['cfg'])\n",
    "        params       = get_params(data_dict, ema_fac)\n",
    "        trajs[kk, 0] = data_dict['xgs'][init_index]\n",
    "        score_net    = launcher.construct_network(cfg)[0]\n",
    "        \n",
    "        # compute the trajectory\n",
    "        for curr_batch in range(nbatches):\n",
    "            lb = curr_batch*bs\n",
    "            ub = lb + bs\n",
    "\n",
    "            start_time = time.time()\n",
    "            trajs[kk, 1+lb:1+ub] = rollout_traj_pflow(trajs[kk, lb], np.arange(bs), score_net, cfg, params, dt)\n",
    "            end_time = time.time()\n",
    "\n",
    "            print(f'[{kk+1}/{len(v0s)}], [{curr_batch+1}/{nbatches}], {end_time-start_time}s.')\n",
    "\n",
    "\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test v0 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xgs       = data_dicts[0.0]['xgs']\n",
    "nsamples       = test_xgs.shape[0]\n",
    "test_cfg       = data_dicts[0.0]['cfg']\n",
    "test_score_net = launcher.construct_network(test_cfg)[0]\n",
    "test_params    = data_dicts[0.0]['ema_params_list'][-1][0.999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind                  = onp.random.randint(nsamples)\n",
    "test_xdot, test_gdot = np.split(pflow_rhs(test_xgs[ind], test_score_net, test_cfg, test_params), 2)\n",
    "test_xdot.min(), test_xdot.max(), np.linalg.norm(test_xdot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfac        = 5.0\n",
    "gamma       = data_dicts[v0s[0]]['cfg'].gamma\n",
    "tf          = tfac / gamma\n",
    "dt          = 0.01\n",
    "ema_fac     = 0.9999\n",
    "nbatches    = 10\n",
    "pflow_trajs = compute_pflow_trajs(tf, nbatches, ema_fac, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_movie(\n",
    "    trajs: np.ndarray, # [ntrajs, nsteps, 2N, d]\n",
    "    save_str: str,\n",
    "    dt: float,\n",
    "    nframes: int = 250\n",
    ") -> None:\n",
    "    plt.close('all')\n",
    "    sns.set_palette('deep')\n",
    "    fw, fh   = 4, 4\n",
    "    fontsize = 20\n",
    "    r_fac    = 1.4\n",
    "    nrows    = 1\n",
    "    ncols    = trajs.shape[0]\n",
    "    nsteps   = trajs.shape[1]\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(fw*ncols, fh*nrows), sharex=True, sharey=True, constrained_layout=True)\n",
    "    width    = data_dicts[v0s[0]]['cfg'].width\n",
    "\n",
    "\n",
    "    ## set axis limits, grids, and particle scaling\n",
    "    cfg = data_dicts[0.0]['cfg']\n",
    "    for ax in axs:\n",
    "        ax.set_xlim([-cfg.width, cfg.width])\n",
    "        ax.set_ylim([-cfg.width, cfg.width])\n",
    "        \n",
    "        ax.set_xticks([-0.5*cfg.width, 0, 0.5*cfg.width],\n",
    "                      [r\"$-L/4$\", r\"$0.0$\", r\"$L/4$\"])\n",
    "        ax.set_yticks([-0.5*cfg.width, 0, 0.5*cfg.width],\n",
    "                      [r\"$-L/4$\", r\"$0.0$\", r\"$L/4$\"])\n",
    "\n",
    "        ax.grid(which='both', axis='both', color='0.90', alpha=0.2)\n",
    "        ax.tick_params(which='both', width=0, length=0, labelsize=fontsize)\n",
    "        ax.set_facecolor('k')\n",
    "        ax.axes.set_aspect(1.0)\n",
    "\n",
    "\n",
    "    ## set up initial scatter plots\n",
    "    scats = []\n",
    "    for kk, (traj, ax) in enumerate(zip(trajs, axs)):\n",
    "        scats.append(\n",
    "            ax.scatter(\n",
    "                traj[0, :N, 0], traj[0, :N, 1], zorder=1, s=radius_to_points(ax, r_fac), marker='o', color='C4', alpha=0.75\n",
    "            )\n",
    "        )\n",
    "        ax.set_title(rf\"$v_0=${v0s[kk]}\", fontsize=fontsize)\n",
    "        fig.suptitle(rf\"$t=${0:0.3f}$/\\gamma$\", fontsize=fontsize)\n",
    "\n",
    "\n",
    "    def init():\n",
    "        return scats\n",
    "\n",
    "\n",
    "    def animate(frame: int):\n",
    "        ## remove scatter for speed\n",
    "        for path_collection in scats:\n",
    "            path_collection.remove()\n",
    "\n",
    "\n",
    "        ## update scatter plot\n",
    "        t = frame*dt*step\n",
    "        \n",
    "        for kk, (traj, ax) in enumerate(zip(trajs, axs)):\n",
    "            scats[kk] = ax.scatter(\n",
    "                traj[frame, :N, 0], traj[frame, :N, 1], zorder=1, s=radius_to_points(ax, r_fac), marker='o', color='C4', alpha=0.75\n",
    "            )\n",
    "        \n",
    "        t = gamma*dt*frame\n",
    "        fig.suptitle(rf\"$t=${t:0.3f}$/\\gamma$\", fontsize=fontsize)\n",
    "\n",
    "        ## return what changed in the plot\n",
    "        if frame % (stop // 10) == 0:\n",
    "            print(f'[{frame}/{stop}]')\n",
    "\n",
    "        return scats\n",
    "\n",
    "    start, stop, step = 0, nsteps, nsteps // nframes\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=onp.arange(start, stop, step), \n",
    "                                   interval=0.1, blit=True, repeat=False, cache_frame_data=False)\n",
    "\n",
    "    save_name = f'{save_str}.mp4'\n",
    "    anim.save(save_name, fps=60)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv0s_plot = 5\n",
    "base_output_folder = '/scratch/nb3397/results/mips/lowd_cates/figures/8_18_23/'\n",
    "\n",
    "make_movie(\n",
    "    pflow_trajs[:nv0s_plot], \n",
    "    f'{base_output_folder}/pflow',\n",
    "    dt=dt,\n",
    "    nframes=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Map Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_params_dict = {}\n",
    "for kk, v0 in enumerate(v0s):\n",
    "    curr_params = get_params(data_dicts[v0], ema_fac=0.9999)\n",
    "    separate_params_dict[v0] = {}\n",
    "\n",
    "    for key in ['x', 'g']:\n",
    "        separate_params_dict[v0][f's{key}'] = {\n",
    "            'g_embedding_params': {key: value for key, value in curr_params[key].items() if 'g_embedding' in key},\n",
    "            'x_embedding_params': {key: value for key, value in curr_params[key].items() if 'x_embedding' in key},\n",
    "            'trans_params'      : {key: value for key, value in curr_params[key].items() if 'transformer' in key},\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate network for attention map computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def g_embedding(\n",
    "    inp: np.ndarray, \n",
    "    cfg: config_dict.FrozenConfigDict\n",
    "):\n",
    "    return hk.Sequential(\n",
    "        networks.construct_mlp_layers(\n",
    "            cfg.embed_n_hidden, cfg.embed_n_neurons, jax.nn.gelu, w0=cfg.w0, \n",
    "            output_dim=cfg.embed_dim // 2, use_layer_norm=False, \n",
    "            use_residual_connections=True, name='g_embedding'\n",
    "        )\n",
    "    )(inp)\n",
    "\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def x_embedding(\n",
    "    inp: np.ndarray,\n",
    "    cfg: config_dict.FrozenConfigDict\n",
    "):\n",
    "    return hk.Sequential(\n",
    "        networks.construct_mlp_layers(\n",
    "            cfg.embed_n_hidden, cfg.embed_n_neurons, jax.nn.gelu, w0=cfg.w0, \n",
    "            output_dim=cfg.embed_dim // 2, use_layer_norm=False, \n",
    "            use_residual_connections=True, name='x_embedding'\n",
    "        )\n",
    "    )(inp)\n",
    "\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def transformer(\n",
    "    inp: np.ndarray,\n",
    "    cfg: config_dict.FrozenConfigDict\n",
    "):\n",
    "     return networks.Transformer(\n",
    "         num_layers=cfg.num_layers, input_dim=cfg.embed_dim,\n",
    "         num_heads=cfg.num_heads, dim_feedforward=cfg.dim_feedforward,\n",
    "         n_layers_feedforward=cfg.n_layers_feedforward,\n",
    "         n_inducing_points=cfg.n_inducing_points, w0=cfg.w0\n",
    "     )(inp)\n",
    "\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def get_transformer_attention(\n",
    "    inp: np.ndarray,\n",
    "    cfg: config_dict.FrozenConfigDict\n",
    "):\n",
    "     return networks.Transformer(\n",
    "         num_layers=cfg.num_layers, input_dim=cfg.embed_dim,\n",
    "         num_heads=cfg.num_heads, dim_feedforward=cfg.dim_feedforward,\n",
    "         n_layers_feedforward=cfg.n_layers_feedforward,\n",
    "         n_inducing_points=cfg.n_inducing_points, w0=cfg.w0\n",
    "     ).get_attention_maps(inp)\n",
    "\n",
    "\n",
    "def attention_rollout(\n",
    "    attention_maps: np.ndarray # [L, N, N]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute the rollout attention map; assumes that we have averaged over all heads.\"\"\"\n",
    "    dim             = attention_maps[0].shape[0]\n",
    "    rollout_attn    = onp.zeros(attention_maps.shape)\n",
    "    I               = onp.eye(dim)\n",
    "    rollout_attn[0] = 0.5*(attention_maps[0] + I)\n",
    "\n",
    "    for ii, curr_attn in enumerate(attention_maps[1:]):\n",
    "        rollout_attn[ii+1] = 0.5*(curr_attn + I) @ rollout_attn[ii]\n",
    "\n",
    "    return rollout_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute attention maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_dict = {}\n",
    "for kk, v0 in enumerate(v0s):\n",
    "    attention_dict[v0] = {}\n",
    "    for key in ['sx', 'sg']:\n",
    "        curr_cfg           = data_dicts[v0]['cfg']\n",
    "        curr_xgs           = data_dicts[v0]['xgs']\n",
    "        curr_xs, curr_gs   = np.split(curr_xgs, 2, axis=1)\n",
    "        curr_params_dict   = separate_params_dict[v0][key]\n",
    "        x_embedding_params = curr_params_dict['x_embedding_params']\n",
    "        g_embedding_params = curr_params_dict['g_embedding_params']\n",
    "        trans_params       = curr_params_dict['trans_params']\n",
    "\n",
    "        \n",
    "        embedded_xs       = x_embedding.apply(x_embedding_params, curr_xs[0], curr_cfg)\n",
    "        embedded_gs       = g_embedding.apply(g_embedding_params, curr_gs[0], curr_cfg)\n",
    "        transformer_input = np.hstack((embedded_xs, embedded_gs))\n",
    "        \n",
    "        \n",
    "        attention_dict[v0]['attention_maps'] = np.array(get_transformer_attention.apply(trans_params, transformer_input, curr_cfg))\n",
    "        attention_dict[v0]['rollout_attn']   = attention_rollout(np.mean(attention_dict[v0]['attention_maps'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standard figure configuration\n",
    "plt.close('all')\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette('deep')\n",
    "fraction = 0.95\n",
    "shrink   = 0.75\n",
    "fontsize = 12.5\n",
    "cmap     = sns.color_palette('mako', as_cmap=True)\n",
    "\n",
    "\n",
    "## what to plot\n",
    "layer   = 0\n",
    "head    = 3\n",
    "v0      = 0.3\n",
    "curr_xs = np.split(data_dicts[v0]['xgs'], 2, axis=1)[0]\n",
    "curr_cfg = data_dicts[v0]['cfg']\n",
    "particle_identity = onp.random.randint(curr_cfg.N)\n",
    "curr_attention_map = attention_dict[v0]['attention_maps'][layer][head]\n",
    "# curr_attention_map = attention_dict[v0]['rollout_attn'][layer]\n",
    "\n",
    "\n",
    "## visualize attention map itself\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(5, 2), constrained_layout=True)\n",
    "vmin = np.min(curr_attention_map)\n",
    "vmax = np.max(curr_attention_map)\n",
    "norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "im   = axs[0].imshow(curr_attention_map, norm=norm, cmap=cmap)\n",
    "cbar = fig.colorbar(im, ax=axs[0], fraction=fraction, shrink=shrink)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "axs[0].grid(which='both', axis='both', color='0.90', alpha=0.0)\n",
    "\n",
    "\n",
    "## visualize attention on the particles\n",
    "c    = curr_attention_map[particle_identity]\n",
    "vmin = np.min(c)\n",
    "vmax = np.max(c)\n",
    "norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "scat = axs[1].scatter(curr_xs[0, :, 0], curr_xs[0, :, 1], s=75, marker='o', c=c, norm=norm, cmap=cmap)\n",
    "cbar = fig.colorbar(scat, ax=axs[1], fraction=fraction, shrink=shrink)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "axs[1].scatter(curr_xs[0, particle_identity, 0], curr_xs[0, particle_identity, 1], s=75, marker='o', color='white', alpha=0.75)\n",
    "axs[1].grid(which='both', axis='both', color='0.90', alpha=0.2)\n",
    "axs[1].set_xlim([-curr_cfg.width//2, curr_cfg.width//2])\n",
    "axs[1].set_ylim([-curr_cfg.width//2, curr_cfg.width//2])\n",
    "axs[1].grid(which='both', axis='both', color='0.90', alpha=0.2)\n",
    "axs[1].axes.set_aspect(1.0)\n",
    "scale = axs[1].transData.get_matrix()[0, 0]\n",
    "axs[1].tick_params(axis='both', labelsize=fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Particle Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multiparticle_attention_map_plot(\n",
    "    attention_map: np.ndarray,\n",
    "    xs: np.ndarray,\n",
    "    nparticles_plot: int,\n",
    "    cfg: config_dict.FrozenConfigDict\n",
    ") -> None:\n",
    "\n",
    "    ## plot parameters\n",
    "    plt.close('all')\n",
    "    sns.set_palette('deep')\n",
    "\n",
    "    fraction = 0.25\n",
    "    shrink   = 0.25\n",
    "    fontsize = 10.0\n",
    "    cmap     = sns.color_palette('mako', as_cmap=True)\n",
    "    nrows    = ncols = nparticles_plot\n",
    "    nparticles_total = nparticles_plot**2\n",
    "    particle_size    = 40\n",
    "\n",
    "    ## what to plot\n",
    "    particle_identity = onp.random.randint(cfg.N)\n",
    "    particle_inds     = onp.random.choice(onp.arange(cfg.N), size=nparticles_total)\n",
    "\n",
    "    ## visualize many particles at once\n",
    "    fw, fh   = 1.5, 1.5\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(fw*ncols, fh*nrows), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "    ## basic plot properties\n",
    "    for ax in axs.ravel():\n",
    "        ax.set_facecolor('k')\n",
    "        ax.set_xlim([-0.75*cfg.width, 0.75*cfg.width])\n",
    "        ax.set_ylim([-0.75*cfg.width, 0.75*cfg.width])\n",
    "        ax.axes.set_aspect(1.0)\n",
    "        scale = ax.transData.get_matrix()[0, 0]\n",
    "\n",
    "        ## for sizing the particles\n",
    "        ax.grid(which='both', axis='both', color='0.90', alpha=0.25)\n",
    "\n",
    "        ## for actual figure\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])   \n",
    "\n",
    "    ## visualize attention-colored particles\n",
    "    for ii in range(nrows):\n",
    "        for jj in range(ncols):\n",
    "            # identify the particle and the corresponding row of the attention map\n",
    "            particle_identity = particle_inds[jj + ii*nrows]\n",
    "            attn = attention_map[particle_identity]\n",
    "            attn = attn / np.sum(attn)\n",
    "\n",
    "            # current colorbar scaling\n",
    "            vmin = np.min(attn)\n",
    "            vmax = np.max(attn)\n",
    "            norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "            # plot other particles\n",
    "            s = radius_to_points(ax, 1.25)\n",
    "            scat = axs[ii, jj].scatter(xs[:, 0], xs[:, 1], s=s, marker='o', c=attn, norm=norm, cmap=cmap, alpha=1.0)\n",
    "\n",
    "            # plot this particle, circled\n",
    "            axs[ii, jj].scatter(\n",
    "                xs[particle_identity, 0], \n",
    "                xs[particle_identity, 1], \n",
    "                s=s, \n",
    "                c=attn[particle_identity], \n",
    "                marker='o', \n",
    "                edgecolor='white',\n",
    "                linewidth=0.25, \n",
    "            )\n",
    "\n",
    "\n",
    "    cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), ax=axs.ravel().tolist(), shrink=shrink, fraction=fraction, orientation='horizontal')\n",
    "    cbar.ax.xaxis.set_ticks([])\n",
    "    cbar.set_label('attention', fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0    = 0.4\n",
    "layer = 3\n",
    "xs    = np.split(data_dicts[v0]['xgs'][0], 2)[0]\n",
    "cfg   = data_dicts[v0]['cfg']\n",
    "head  = 3\n",
    "\n",
    "\n",
    "## raw attention\n",
    "# make_multiparticle_attention_map_plot(attention_dict[v0]['attention_maps'][layer][head], xs, cfg)\n",
    "\n",
    "## rollout attention\n",
    "make_multiparticle_attention_map_plot(attention_dict[v0]['rollout_attn'][layer], xs, nparticles_plot=2, cfg=cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Particle, Multi-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_v0_attention_map_plot(\n",
    "    v0s_plot: list,\n",
    "    nparticles_plot: int,\n",
    "    clip_quantile: float,\n",
    "    save_str: str\n",
    ") -> None:\n",
    "    ## plot parameters\n",
    "    plt.close('all')\n",
    "    sns.set_palette('deep')\n",
    "    fraction  = 0.1\n",
    "    pad       = 0.025\n",
    "    shrink    = 0.5\n",
    "    fontsize  = 20\n",
    "    titles    = [rf\"$v_0={v0}$\" for v0 in v0s_plot]\n",
    "    cmap      = sns.color_palette('mako', as_cmap=True)\n",
    "    nrows     = nparticles_plot\n",
    "    ncols     = len(titles)\n",
    "\n",
    "\n",
    "    ## visualize many particles at once\n",
    "    fw, fh   = 4, 5.0\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, \n",
    "                            figsize=(fw*ncols, fh*nrows), \n",
    "                            sharex=True, sharey=True, \n",
    "                            constrained_layout=True)\n",
    "    axs = axs.reshape((nrows, ncols))\n",
    "\n",
    "    ## pre-select particles\n",
    "    particle_inds = onp.random.choice(onp.arange(N), replace=False, size=nparticles_plot)\n",
    "    \n",
    "    \n",
    "    ## single colorbar\n",
    "    normalized_attns = onp.zeros((nrows, ncols, N))\n",
    "    for ii, particle_ind in enumerate(particle_inds):\n",
    "        for jj, v0 in enumerate(v0s_plot):\n",
    "            curr_attn = attention_dict[v0]['rollout_attn'][-1][particle_ind]\n",
    "            normalized_attns[ii, jj] = curr_attn / onp.sum(curr_attn)\n",
    "\n",
    "    vmin       = onp.quantile(normalized_attns, q=clip_quantile)\n",
    "    vmax       = onp.quantile(normalized_attns, q=(1-clip_quantile))\n",
    "    normalized_attns[normalized_attns < vmin] = vmin\n",
    "    normalized_attns[normalized_attns > vmax] = vmax\n",
    "    norm       = mpl.colors.Normalize(vmin=vmin, vmax=vmax, clip=True)\n",
    "    mappable   = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    mappable.set_array([])\n",
    "\n",
    "    ## make the plot\n",
    "    vmin, vmax = np.inf, -np.inf\n",
    "    for ii in range(nrows):\n",
    "        particle_identity = particle_inds[ii]\n",
    "\n",
    "        for jj, v0 in enumerate(v0s_plot):\n",
    "            ## unpack\n",
    "            cfg = data_dicts[v0]['cfg']\n",
    "            xs = np.split(data_dicts[v0]['xgs'][0], 2)[0]\n",
    "\n",
    "\n",
    "            ## update basic visual aspects\n",
    "            ax = axs[ii, jj]\n",
    "            ax.set_facecolor('k')\n",
    "            ax.set_xlim([-0.85*cfg.width, 0.85*cfg.width])\n",
    "            ax.set_ylim([-0.85*cfg.width, 0.85*cfg.width])\n",
    "            ax.set_xticks([-0.75*cfg.width, 0, 0.75*cfg.width],\n",
    "                          [r\"$-3L/8$\", r\"$0.0$\", r\"$3L/8$\"])\n",
    "            ax.set_yticks([-0.75*cfg.width, 0, 0.75*cfg.width],\n",
    "                          [r\"$-3L/8$\", r\"$0.0$\", r\"$3L/8$\"])\n",
    "            ax.tick_params(which='both', width=0, length=0, labelsize=fontsize)\n",
    "            \n",
    "            \n",
    "            if ii == 0:\n",
    "                ax.set_title(titles[jj], fontsize=fontsize)\n",
    "            ax.axes.set_aspect(1.0)\n",
    "            ax.grid(which='both', axis='both', color='0.90', alpha=0.05)\n",
    "            ax.tick_params(axis='both', length=0, width=0, labelsize=fontsize)\n",
    "            s = radius_to_points(ax, 1.35)\n",
    "\n",
    "\n",
    "            ## plot the attention\n",
    "#             attn = attention_dict[v0]['rollout_attn'][-1][particle_identity]\n",
    "#             attn = attn / np.sum(attn)\n",
    "#             vmin, vmax = attn.min(), attn.max()\n",
    "#             norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "            attn = normalized_attns[ii, jj]\n",
    "            scat = ax.scatter(     xs[:, 0],                     xs[:, 1], s=s, c=attn,                    marker='o', norm=norm, cmap=cmap, alpha=0.75)\n",
    "            ax.scatter(xs[particle_identity, 0], xs[particle_identity, 1], s=s, c=attn[particle_identity], marker='o', norm=norm, cmap=cmap, edgecolor='white', linewidth=0.1)\n",
    "\n",
    "    cbar = fig.colorbar(mappable=mappable, norm=norm, ax=axs.ravel().tolist(), shrink=shrink, fraction=fraction, orientation='vertical')\n",
    "    cbar.ax.xaxis.set_ticks([])\n",
    "    cbar.ax.yaxis.set_ticks([])\n",
    "    cbar.set_label('attention', fontsize=fontsize)\n",
    "\n",
    "\n",
    "    if save_str != None:\n",
    "        fig.patch.set_facecolor('k')\n",
    "        fig.patch.set_alpha(0.0)\n",
    "        plt.savefig(f'{save_str}.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_output_folder = '/scratch/nb3397/results/mips/lowd_cates/figures/8_18_23/'\n",
    "base_output_folder = '/scratch/nb3397/results/mips/lowd_cates/figures/9_20_23/'\n",
    "make_v0_attention_map_plot(v0s_plot=v0s[1:-1], nparticles_plot=1, clip_quantile=0.02, save_str=f'{base_output_folder}/attention')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
